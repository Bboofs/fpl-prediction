{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.stats import uniform, randint\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to project directory\n",
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in training dataset\n",
    "train_df = pd.read_csv(path/'data/train_v4.csv', index_col=0, dtype={'season':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model\n",
    "\n",
    "XGboost is a ensemble tree-based predictive algorithm that performs well across a range of applications. Applying it to a time series problem, where metrics from recent time periods can be predicitve, requires us to add in window features (e.g. points scored last gameweek). These are created using the player_lag_features function from 00_fpl_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a bunch of player lag features\n",
    "lag_train_df, player_lag_vars = player_lag_features(train_df, ['total_points'], ['all', 1, 2, 3, 4, 5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have introduced a number of lag (window) features for each player's average points per game over the previous 1, 2, 3, 4, 5, 10 and all gameweeks.\n",
    "\n",
    "Next we can set the validation point and length as well as the categorical and continuous features we'll be using to predict the dependent variable, total points for each game. These are used in the create_lag_train function to get an our training set (including appropriate lag values in the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set validaton point/length and categorical/continuous variables\n",
    "valid_season = '1920'\n",
    "valid_gw = 20\n",
    "valid_len = 6\n",
    "cat_vars = ['season', 'position', 'team', 'opponent_team', 'was_home']\n",
    "cont_vars = ['gw', 'minutes']\n",
    "dep_var = ['total_points']\n",
    "\n",
    "# create dataset with adjusted post-validation lag numbers\n",
    "lag_train_df, train_idx, valid_idx = create_lag_train(lag_train_df, \n",
    "                                                      cat_vars, cont_vars, player_lag_vars, dep_var,\n",
    "                                                      valid_season, valid_gw, valid_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82054 entries, 0 to 82053\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   index                     82054 non-null  int64  \n",
      " 1   player                    82054 non-null  object \n",
      " 2   season                    82054 non-null  object \n",
      " 3   position                  82054 non-null  int64  \n",
      " 4   team                      82054 non-null  object \n",
      " 5   opponent_team             82054 non-null  object \n",
      " 6   was_home                  82054 non-null  bool   \n",
      " 7   gw                        82054 non-null  int64  \n",
      " 8   minutes                   82054 non-null  int64  \n",
      " 9   total_points_pg_last_all  68666 non-null  float64\n",
      " 10  total_points_pg_last_1    37879 non-null  float64\n",
      " 11  total_points_pg_last_2    44333 non-null  float64\n",
      " 12  total_points_pg_last_3    47807 non-null  float64\n",
      " 13  total_points_pg_last_4    50292 non-null  float64\n",
      " 14  total_points_pg_last_5    52087 non-null  float64\n",
      " 15  total_points_pg_last_10   57642 non-null  float64\n",
      " 16  total_points              82054 non-null  int64  \n",
      "dtypes: bool(1), float64(7), int64(5), object(4)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# take a look at the dataframe\n",
    "lag_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build the input (X) and dependent (y) variable datasets. This includes encoding the categorical features so that each level is represented in it's own column (e.g. postition_1, position_2, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out dependent variable\n",
    "X, y = lag_train_df[cat_vars + cont_vars + player_lag_vars].copy(), lag_train_df[dep_var].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since position is categorical, it should be a string\n",
    "X['position'] = X['position'].apply(str)\n",
    "\n",
    "# need to transform season\n",
    "enc = LabelEncoder()\n",
    "X['season'] = enc.fit_transform(X['season'])\n",
    "X_dict = X.to_dict(\"records\")\n",
    "\n",
    "# Create the DictVectorizer object: dv\n",
    "dv = DictVectorizer(sparse=False, separator='_')\n",
    "\n",
    "# Apply dv on df: df_encoded\n",
    "X_encoded = dv.fit_transform(X_dict)\n",
    "\n",
    "X_df = pd.DataFrame(X_encoded, columns=dv.feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the resulting dataset with the categorical features split out into levels. This can now be used in the XGBoost API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82054 entries, 0 to 82053\n",
      "Data columns (total 73 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   gw                                      82054 non-null  float64\n",
      " 1   minutes                                 82054 non-null  float64\n",
      " 2   opponent_team_Arsenal                   82054 non-null  float64\n",
      " 3   opponent_team_Aston Villa               82054 non-null  float64\n",
      " 4   opponent_team_Bournemouth               82054 non-null  float64\n",
      " 5   opponent_team_Brighton and Hove Albion  82054 non-null  float64\n",
      " 6   opponent_team_Burnley                   82054 non-null  float64\n",
      " 7   opponent_team_Cardiff City              82054 non-null  float64\n",
      " 8   opponent_team_Chelsea                   82054 non-null  float64\n",
      " 9   opponent_team_Crystal Palace            82054 non-null  float64\n",
      " 10  opponent_team_Everton                   82054 non-null  float64\n",
      " 11  opponent_team_Fulham                    82054 non-null  float64\n",
      " 12  opponent_team_Huddersfield Town         82054 non-null  float64\n",
      " 13  opponent_team_Hull City                 82054 non-null  float64\n",
      " 14  opponent_team_Leicester City            82054 non-null  float64\n",
      " 15  opponent_team_Liverpool                 82054 non-null  float64\n",
      " 16  opponent_team_Manchester City           82054 non-null  float64\n",
      " 17  opponent_team_Manchester United         82054 non-null  float64\n",
      " 18  opponent_team_Middlesbrough             82054 non-null  float64\n",
      " 19  opponent_team_Newcastle United          82054 non-null  float64\n",
      " 20  opponent_team_Norwich                   82054 non-null  float64\n",
      " 21  opponent_team_Sheffield United          82054 non-null  float64\n",
      " 22  opponent_team_Southampton               82054 non-null  float64\n",
      " 23  opponent_team_Stoke City                82054 non-null  float64\n",
      " 24  opponent_team_Sunderland                82054 non-null  float64\n",
      " 25  opponent_team_Swansea City              82054 non-null  float64\n",
      " 26  opponent_team_Tottenham Hotspur         82054 non-null  float64\n",
      " 27  opponent_team_Watford                   82054 non-null  float64\n",
      " 28  opponent_team_West Bromwich Albion      82054 non-null  float64\n",
      " 29  opponent_team_West Ham United           82054 non-null  float64\n",
      " 30  opponent_team_Wolverhampton Wanderers   82054 non-null  float64\n",
      " 31  position_1                              82054 non-null  float64\n",
      " 32  position_2                              82054 non-null  float64\n",
      " 33  position_3                              82054 non-null  float64\n",
      " 34  position_4                              82054 non-null  float64\n",
      " 35  season                                  82054 non-null  float64\n",
      " 36  team_Arsenal                            82054 non-null  float64\n",
      " 37  team_Aston Villa                        82054 non-null  float64\n",
      " 38  team_Bournemouth                        82054 non-null  float64\n",
      " 39  team_Brighton and Hove Albion           82054 non-null  float64\n",
      " 40  team_Burnley                            82054 non-null  float64\n",
      " 41  team_Cardiff City                       82054 non-null  float64\n",
      " 42  team_Chelsea                            82054 non-null  float64\n",
      " 43  team_Crystal Palace                     82054 non-null  float64\n",
      " 44  team_Everton                            82054 non-null  float64\n",
      " 45  team_Fulham                             82054 non-null  float64\n",
      " 46  team_Huddersfield Town                  82054 non-null  float64\n",
      " 47  team_Hull City                          82054 non-null  float64\n",
      " 48  team_Leicester City                     82054 non-null  float64\n",
      " 49  team_Liverpool                          82054 non-null  float64\n",
      " 50  team_Manchester City                    82054 non-null  float64\n",
      " 51  team_Manchester United                  82054 non-null  float64\n",
      " 52  team_Middlesbrough                      82054 non-null  float64\n",
      " 53  team_Newcastle United                   82054 non-null  float64\n",
      " 54  team_Norwich                            82054 non-null  float64\n",
      " 55  team_Sheffield United                   82054 non-null  float64\n",
      " 56  team_Southampton                        82054 non-null  float64\n",
      " 57  team_Stoke City                         82054 non-null  float64\n",
      " 58  team_Sunderland                         82054 non-null  float64\n",
      " 59  team_Swansea City                       82054 non-null  float64\n",
      " 60  team_Tottenham Hotspur                  82054 non-null  float64\n",
      " 61  team_Watford                            82054 non-null  float64\n",
      " 62  team_West Bromwich Albion               82054 non-null  float64\n",
      " 63  team_West Ham United                    82054 non-null  float64\n",
      " 64  team_Wolverhampton Wanderers            82054 non-null  float64\n",
      " 65  total_points_pg_last_1                  37879 non-null  float64\n",
      " 66  total_points_pg_last_10                 57642 non-null  float64\n",
      " 67  total_points_pg_last_2                  44333 non-null  float64\n",
      " 68  total_points_pg_last_3                  47807 non-null  float64\n",
      " 69  total_points_pg_last_4                  50292 non-null  float64\n",
      " 70  total_points_pg_last_5                  52087 non-null  float64\n",
      " 71  total_points_pg_last_all                68666 non-null  float64\n",
      " 72  was_home                                82054 non-null  float64\n",
      "dtypes: float64(73)\n",
      "memory usage: 45.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82054 entries, 0 to 82053\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   total_points_pg_last_all  68666 non-null  float64\n",
      " 1   total_points_pg_last_1    37879 non-null  float64\n",
      " 2   total_points_pg_last_2    44333 non-null  float64\n",
      " 3   total_points_pg_last_3    47807 non-null  float64\n",
      " 4   total_points_pg_last_4    50292 non-null  float64\n",
      " 5   total_points_pg_last_5    52087 non-null  float64\n",
      " 6   total_points_pg_last_10   57642 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "X[player_lag_vars].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by instatiating an XGBRegressor (since the dependent variable is continuous) and do a single train with arbitrary parameters. We split out the validation set and use it after training to create predictions and calculate the RMSE versus actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out training and validation sets\n",
    "X_train = X_df.iloc[train_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "X_test = X_df.iloc[valid_idx]\n",
    "y_test = y.iloc[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.791749\n"
     ]
    }
   ],
   "source": [
    "# instatiate and train XGB Regressor\n",
    "# print result\n",
    "xg_reg = xgb.XGBRegressor(gamma=0.05, learning_rate=0.08, max_depth=5, n_estimators=75, subsample=0.7)\n",
    "\n",
    "xg_reg.fit(X_train, y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "print(\"RMSE: %f\" % (r_mse(preds, y_test['total_points'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a clear improvement on the baseline approach, but perhaps it can be improved by doing a parameter search.\n",
    "\n",
    "To do this we will first define the grid of parameters to be searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter search space\n",
    "params = {#\"colsample_bytree\": uniform(0.7, 0.3),\n",
    "          \"gamma\": uniform(0, 0.5),\n",
    "          \"learning_rate\": uniform(0.003, 0.3), # default 0.1 \n",
    "          \"max_depth\": randint(2, 6), # default 3\n",
    "          \"n_estimators\": randint(25, 200), # default 100\n",
    "          \"subsample\": uniform(0.6, 0.4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will pass both train and validation parts of the dataset, along with a series telling the XGBRegressor object which rows to use for training, and which for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_df\n",
    "y_train = y\n",
    "test_fold = np.repeat([-1, 0], [valid_idx[0], valid_idx[-1] - valid_idx[0] + 1])\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then again instatiate the XGBRegressor object, but this time pass it to a randomised search validation object, along with the parameter grid, validation splits, and number of iterations we want to run.\n",
    "\n",
    "We then fit this to the training data - 25 random parameter selections will be made and the best parameters for the validation set can be found (may take a few minutes to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 25 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'gamma': 0.2819157508996368, 'learning_rate': 0.12981570144081725, 'max_depth': 3, 'n_estimators': 174, 'subsample': 0.9465078528713007}\n",
      "Lowest RMSE found:  1.7893024515231921\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "\n",
    "# Perform random search: grid_mse\n",
    "randomized_mse = RandomizedSearchCV(estimator=gbm, \n",
    "                            param_distributions=params, \n",
    "                            scoring=\"neg_mean_squared_error\", \n",
    "                            n_iter=25, \n",
    "                            cv=ps, \n",
    "                            verbose=1)\n",
    "\n",
    "# Fit randomized_mse to the data\n",
    "randomized_mse.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", randomized_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(randomized_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight improvement on the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid: gbm_param_grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    #'colsample_bytree': [0.1, 0.5, 0.8, 1],\n",
    "    'learning_rate': [0.1]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
